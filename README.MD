
# تحلیل داده‌های هواشناسی و الگوهای بارش در شهرهای ایران

##  معرفی پروژه

این پروژه با هدف بهبود عملکرد رستوران ها بر اساس کامنت های کاربرانی که از آن ها سفارشی داشته اند، انجام شده است. تمرکز اصلی پروژه، پیدا کردن عوامل موثر در کاهش امتیاز ها و هم چنین پیش بینی میانگین امتیاز آن رستوران در هفته آینده است. این پروژه در دو مرحله که بخش های مختلفی را دارد تشکیل شده است، که بصورت کامل در ادامه توضیح داده خواهد شد.

##  پیش‌ نیاز ها

برای اجرای این پروژه نیاز به نصب پکیج‌ های زیر دارید که در فایل `requirements.txt` نیز آمده است:

```
fastapi
uvicorn
pandas
numpy
scikit-learn
xgboost
joblib
cudf

```

نصب با دستور:
```bash
pip install -r requirements.txt
```

## مراحل انجام پروژه

### 1. خواندن داده‌ ها

داده‌ هایی که بر روی آن ها کار شده است از سایت [snappfood-comments](https://www.kaggle.com/datasets/moeinkpr/snappfood-comments)  گرفته شده است. لازم به ذکر است که این دیتاست شامل رستوران ها، کافه ها، سوپر مارکت ها  و قنادی ها است که در پروژه فقط رستوران ها را در نظر گرفتیم زیرا 83 درصد از دیتاست را کامنت های فقط مربوط به رستوران ها پوشش می دهد که در مقایسه با دیگر دسته بندی ها ارزش بیشتری دارند.

### 2. پیش پردازش بر روی داده ‌ها

در دیتاست موجود ستون هایی وجود داشت که مقادیر آن ها یکسان بودند.از این رو برای کاهش حجم ابعاد یکی از آن ستون ها را در نظر می گرفتیم مانند [title, highlight]  در فایل vendor.csv و [rating,rate] در فایل comments.csv. هم چنین ستون هایی وجود دارد که ارزش تحلیل و بررسی ندارند، مانند[commentId,sender,customerId,feeling,status,replies] در فایل comments.csv و ستون های [id,description,address] در vendors.csv  . برای کاهش حجم فایل داده از تابع  `auto_data_type`  استفاده شده است که همه داده ها را بررسی کرده و آن ها را به دیتا تایپی که باعث می شود حجم کمتری بگیرد و داده ای از بین نرود، تبدیل کند. این کار باعث می شود حافظه کمتری مصرف شود. هم چنین وجود داده های تکراری و خالی نیز بررسی شده است که در ستون نظرات مربوط به بخش پیک(deliveryComment)، بیشتر رکورد ها خالی بودند و برای این که در روند پروژه تداخلی ایجاد نشود آن ها را با یک فاصله پر کردیم  سپس با ستون commentText مرج کردیم. در گام بعدی تاریخ ایجاد کامنت را به سال و هفته تفکیک شده است که بتوان تحلیل هفتگی بهتری داشته باشیم. ستون expeditionType را نیز انکود شده است تا حجم داده کاهش یابد.
 همان طور که در شکل زیر مشخص است پس از تبدیل نوع داده ها با کاهش حجم حدود 43 درصد مواجه شدیم.

![پیش_پردازش_داده ها](images/pre_processing.png)



### 3.  فاز اول(تشخصیص عوامل تاثیر گذار در کاهش امتیاز)
### 3-1  پردازش بر روی متن
در ابتدا یک مجموعه کامل از stop_words فارسی دانلود و در پردازش نظرات مشتریان استفاده می کنیم. در گام بعد با استفاده از کتابخانه hazm عملیات پیش پردازش متن و خوشه بندی کلمات انجام گرفت. در تابع preprocess_text هر کامنت ابتدا نرمال سازی شده و سپس مراحلی شامل حذف کاراکترهای غیر فارسی، اعداد و فاصله های اضافی، توکن سازی، حذف کلمات توقف و در نهایت ریشه یابی انجام می شود تا متن برای مراحل بعدی آماده شود. از آنجا که کتابخانه hazm  تنها بر روی CPU اجرا می شود، لازم است پیش از پردازش داده ها از قالب cudf به دیتا فریمpandas   تبدیل شوند و پس از اتمام مرحله پیش پردازش، مجددا به cudf بازگردانده شوند. در ادامه مجموعه ای از دسته بندی های پیش فرض مانند کیفیت، قیمت، ارسال، بسته بندی و غیره مشخص می شود تا مسیر خوشه بندی کلمات مشخص باشد. سپس مدل Word2Vec بر روی جملات آموزش داده می شود تا بردار عددی هر کلمه ساخته شود. در نهایت با استفاده از الگوریتم KMeans کلمات بر اساس شباهت برداری در دسته های مختلف گروه بندی می شوند و هر دسته به نزدیک ترین مفهوم معنایی اختصاص می یابد.



### 3-2   برچسب گذاری
در این بخش از کد هدف اصلی شناسایی عوامل موثر بر رضایت یا نارضایتی مشتریان هر رستوران است. برای این منظور ابتدا نظرات مشتریان به دو دسته مثبت و منفی تقسیم می شوند تا بتوان مدل یادگیری ماشین را بر اساس آن آموزش داد. به همین دلیل تمامی امتیازهایی که مقدارشان 4 یا بیشتر بود به عنوان نظرات مثبت در نظر گرفته شدند (البته این مقدار قابل تغییر است). در مقابل امتیازهای کمتر از 4 به عنوان نظرات منفی تلقی شدند زیرا معمولاً بیانگر نارضایتی نسبی یا کامل از تجربه مشتری هستند.
در ادامه رستوران ها بر اساس کد مخصوصشان گروه بندی می شوند تا برای هر رستوران به صورت مستقل یک مدل ساخته و آموزش داده شود. با این حال تنها رستوران هایی وارد فرایند آموزش شدند که حداقل 30 نظر داشتند. علت این محدودیت آن است که برای دستیابی به نتایج قابل اعتماد نیاز به حجم مناسبی از داده وجود دارد؛ در غیر این صورت مدل ممکن است دچار بیش برازش (overfitting) شود و نتایج غیرواقعی تولید کند.
پس از آماده سازی داده ها شش ویژگی اصلی شامل کیفیت، ارسال، قیمت، بسته بندی، مقدار و خطای سفارش به عنوان شاخص هایی انتخاب شدند که بیشترین احتمال را در تاثیرگذاری بر رضایت مشتریان دارند. سپس مدل XGBoostclassifier بر اساس این ویژگی ها آموزش داده شد تا بتواند تشخیص دهد که کدام یک از این عوامل نقش بیشتری در مثبت یا منفی بودن امتیازهای هر رستوران دارد. در نهایت سه عامل برتر از نظر اهمیت برای هر رستوران استخراج شدند تا مشخص شود کدام عوامل بیشترین تاثیر را بر تجربه مشتریان آن رستوران داشته اند.


### 4.  فاز دوم (پیش بینی امتیاز ) 


### 4-2   ساخت ویژگی
در این مرحله برای آنکه بتوان پیش بینی دقیق تر و قابل اعتمادتری انجام داد، لازم است ویژگی های بیشتری به داده ها اضافه شود تا مدل بتواند تغییرات را بهتر درک کرده و امتیاز آینده را دقیق تر پیش بینی کند. در ابتدا متغیرهای تأخیری مانند rate_lag1 تا rate_lag4 ایجاد می شوند که به ترتیب میانگین امتیاز هفته های قبل را نشان می دهند. این متغیرها به مدل کمک می کنند تا وابستگی زمانی میان امتیازهای متوالی را درک کند، زیرا معمولاً عملکرد یک رستوران در هفته های مختلف با یکدیگر مرتبط است. سپس متغیر delta_rate به عنوان اختلاف میانگین امتیاز هفته جاری و هفته قبل محاسبه می شود. اگر مقدار آن مثبت باشد نشان دهنده افزایش رضایت و اگر منفی باشد بیانگر کاهش عملکرد است.

 متغیر delta2_rate نیز تغییر میانگین امتیاز بین هفته قبل و دو هفته قبل را نشان می دهد. با استفاده از این دو متغیر شاخص دیگری با نام acceleration_rate ساخته می شود که تفاوت بین این تغییرات را بیان می کند. این متغیر در واقع سرعت رشد یا افت امتیاز را اندازه گیری می کند و نشان می دهد روند تغییرات رضایت مشتریان به چه صورت است. در ادامه متغیرهای rolling_mean_2w، rolling_mean_3w و rolling_mean_4w محاسبه می شوند که به ترتیب میانگین امتیاز دو، سه و چهار هفته اخیر را نشان می دهند. در نهایت متغیر y_next به عنوان میانگین امتیاز هفته آینده ساخته می شود که نقش متغیر هدف را دارد و مدل یادگیری ماشین باید مقدار آن را بر اساس سایر متغیرها پیش بینی کند.

### 4-3 آموزش مدل

در این بخش مدل یادگیری ماشین برای پیش بینی میانگین امتیاز هفته آینده رستوران ها آموزش داده می شود. در ابتدا داده ها از قالب cudf به pandas dataframe تبدیل می شوند تا بتوان از مدل های موجود در کتابخانه scikit-learn و XGBoost به راحتی استفاده کرد. سپس ستون های مربوط به کد رستوران، سال، هفته و متغیر هدف y_next از داده ها حذف می شوند تا سایر ستون هایی که در بخش قبلی به عنوان ویژگی ساخته شده اند در مدل مورد استفاده قرار گیرند. در این مرحله تمام داده ها برای آموزش و پیش بینی استفاده می شوند و داده ها به مجموعه های آموزش و آزمون تقسیم نمی شوند. دلیل این تصمیم آن است که داده های پروژه ماهیت زمانی و پیوسته دارند و هر ردیف از داده ها به ترتیب زمانی به هفته قبل و بعد خود وابسته است. اگر داده ها به صورت تصادفی به دو بخش تقسیم شوند، این پیوستگی زمانی از بین می رود و مدل الگوهای واقعی تغییرات را به درستی یاد نمی گیرد.
از سوی دیگر حجم داده ها برای بعضی از رستوران ها نسبتاً محدود است و در صورت حذف بخشی از داده ها، مدل اطلاعات کافی برای یادگیری روندها و الگوهای اصلی نخواهد داشت. بنابراین از کل داده ها استفاده شده تا مدل بیشترین اطلاعات ممکن را از رفتار زمانی امتیازها در اختیار داشته باشد و بتواند الگوهای افزایش یا کاهش رضایت مشتریان را دقیق تر شناسایی کند. در ادامه با تنظیم و تغییر پارامترهای مدل توانستیم به مقادیر مناسبی در معیارهای ارزیابی مانند MAE و R² دست پیدا کنیم که جزئیات آن در بخش ارزیابی پروژه بررسی خواهد شد.

### 4-4 پیش بین امتیاز هفته آینده

در این بخش هدف مان پیش بینی میانگین امتیاز هفته آینده برای هر رستوران با استفاده از مدل آموزش دیده در مرحله قبل است. در ابتدا تابع build_weekly_data  فراخوانی می شود تا داده های خام به داده های هفتگی تبدیل شوند و ویژگی های زمانی مورد نیاز مانند میانگین امتیازها، متغیرهای تأخیری و میانگین های متحرک محاسبه گردند. سپس برای هر رستوران آخرین رکورد مربوط به آخرین هفته در دسترس انتخاب می شود، زیرا مدل قرار است امتیاز هفته بعد از همین نقطه زمانی را پیش بینی کند.
در گام بعدی داده ها از قالب cudf به pandas dataframe تبدیل می شوند تا بتوان از مدل XGBoost برای انجام پیش بینی استفاده کرد. سپس ویژگی هایی که در مرحله آموزش مدل انتخاب شده بودند از داده های آخرین هفته استخراج می شوند و به مدل داده می شوند تا مقدار پیش بینی شده برای امتیاز هفته آینده محاسبه شود. خروجی مدل شامل میانگین امتیاز پیش بینی شده برای هفته آینده است.
در ادامه یک جدول جدید ساخته می شود که شامل کد هر رستوران، میانگین امتیاز هفته گذشته (last_mean_rate) و امتیاز پیش بینی شده هفته آینده است. سپس متغیر expected_change محاسبه می شود که اختلاف بین میانگین امتیاز فعلی و پیش بینی شده را نشان می دهد. در نهایت نتایج بر اساس مقدار expected_change مرتب می شوند تا مشخص شود کدام رستوران ها احتمال بهبود عملکرد دارند و کدام ها ممکن است کاهش امتیاز را تجربه کنند.



## 📊 ارزیابی پروژه
### فاز اول

.نمودار زیر نشان دهنده آن است که، از ویژگی هایی که ساخته شد، چه عواملی به مدلی بیشتر کمک کرده است تا ارتباط بین امتیاز و عوامل را یاد بگیرد
همان طور که مشخص است میانگین های هفتگی تاثیر بیشتری  داشته اند.
![مهم_ترین_ویژگی](images/feature_importance_phase1.png)


از جدول زیر می توان استنباط کرد که نتایج پیش بینی با نتایج واقعی مقداری تفاوت دارد. لازم به ذکر است که این جدول میانگینی است از همه رستوران ها.ممکن است که رستورانی خطای بیشتری داشته باشد در حالی که رستوران دیگر خطای کمتری داشته باشد. دلیل آن که بعضی رستوران ها خطای زیادی دارند این است که تعداد کامنت هایی که برای آن رستوران است مقدار شان کم است و این عامل باعث می شود که مدل برای آن رستوران سو گیری کند. اگر چه یک سری محددیت بر روی  رستوران ها گذاشته شد، تا این خطا به حداقل برسد.

|   MAE   |   MSE   |  RMSE  |   R²   | Train Time (s) | Predict Time (s) |
|:-------:|:-------:|:------:|:------:|:---------------:|:----------------:|
| 1.4546  | 3.8147  | 1.9531 | 0.4629 |       1.85      |       0.02       |


 از نمودار زیر می توان استنباط کرد که در iteration های ابتدایی، مدل سریع ارتباط بین داده ها را پیدا مرده است، در حالی که بعد از iteration=100 مدل بهتر آموزرش می بیند ا

![متریک_فاز1](images/chart_phase1.png)



### فاز دوم
همان طور که از جدول زیر مشخص است، مدل به خوبی توانسته است ارتباط بین عوامل تاثیر گذار در کاهش امتیاز با امتیاز آن رستوران را به خوبی دریابد.

| Accuracy | Precision | Recall | F1     |
|-----------|------------|--------|--------|
| 0.8309    | 0.8330     | 0.9915 | 0.9015 |



## دمو پروژه

برای اجرای عملی مدل و مشاهده کاربرد آن، یک سرویس FastAPI طراحی شد که خروجی‌های مدل را از طریق یک endpoint در اختیار کاربر قرار می‌دهد. این سرویس در سایت Render مستقر شده تا بدون نیاز به اجرای محلی، همیشه در دسترس باشد. با ارسال درخواست به این API (برای مثال با پارامتر code به‌عنوان شناسه رستوران)، پاسخ شامل امتیاز پیش‌بینی‌شده هفته آینده و سایر اطلاعات مرتبط برگردانده می‌شود. به این ترتیب می‌توان به‌راحتی از هر نقطه، چه از طریق کدهای تحلیل و چه از طریق رابط کاربری، امتیاز پیش‌بینی‌شده هر رستوران را دریافت کرد.

در کنار این API، یک وب‌سایت نیز توسعه داده شده که محیطی داشبوردی برای مشاهده و تعامل با نتایج فراهم می‌کند؛ از جمله نمایش روند امتیازها و پیش‌بینی‌ها برای هر رستوران. دسترسی به این داشبورد از طریق آدرس زیر امکان‌پذیر است:
آدرس وب‌سایت: [آدرس سایت را اینجا قرار دهید]

## 📁 ساختار پوشه‌ها

```

restaurant-performance-advisor/
│
├── api/
├── model.pkl 
├── predict.py 
├── weakly_data.csv 
│
└── images/ 
├── pre_processing.png 
├── outlyer.png 
├── scaling.png  
├── heatmap.png 
├── Average_precipitation.png 
├── Annual_precipitation.png 
├── precipitation.png 
└── output.png 
```
